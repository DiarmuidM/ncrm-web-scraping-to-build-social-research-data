{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Practical exercise: Australian charities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Computational methods for collecting, cleaning and analysing data are an increasingly important component of a social scientistâ€™s toolkit. Central to engaging in these methods is the ability to write readable and effective code using a programming language.\n",
    "\n",
    "In this practical we attempt to scrape information on the organisational status of Australian charities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aims\n",
    "\n",
    "This practical has one aim:\n",
    "1. Successfully scrape information relating to Australian charities' organisational status e.g., does it still operate? When was it registered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Guide to using this resource\n",
    "\n",
    "This learning resource was built using <a href=\"https://jupyter.org/\" target=_blank>Jupyter Notebook</a>, an open-source software application that allows you to mix code, results and narrative in a single document. As <a href=\"https://jupyter4edu.github.io/jupyter-edu-book/\" target=_blank>Barba et al. (2019)</a> espouse:\n",
    "> In a world where every subject matter can have a data-supported treatment, where computational devices are omnipresent and pervasive, the union of natural language and computation creates compelling communication and learning opportunities.\n",
    "\n",
    "If you are familiar with Jupyter notebooks then skip ahead to the main content (*What is web-scraping?*). Otherwise, the following is a quick guide to navigating and interacting with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interaction\n",
    "\n",
    "**You only need to execute the code that is contained in sections which are marked by `In []`.**\n",
    "\n",
    "To execute a cell, click or double-click the cell and press the `Run` button on the top toolbar (you can also use the keyboard shortcut Shift + Enter).\n",
    "\n",
    "Try it for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Enter your name and press enter:\")\n",
    "name = input()\n",
    "print(\"\\r\")\n",
    "print(\"Hello {}, enjoy learning more about Python and web-scraping!\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Learn more\n",
    "\n",
    "Jupyter notebooks provide rich, flexible features for conducting and documenting your data analysis workflow. To learn more about additional notebook features, we recommend working through some of the <a href=\"https://github.com/darribas/gds19/blob/master/content/labs/lab_00.ipynb\" target=_blank>materials</a> provided by Dani Arribas-Bel at the University of Liverpool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is the general approach for scraping data from a web page?\n",
    "\n",
    "We begin by identifying a web page containing information we are interested in collecting. Then we need to **know** the following:\n",
    "1. The location (i.e., web address) where the web page can be accessed. For example, the UK Data Service homepage can be accessed via <a href=\"https://ukdataservice.ac.uk/\" target=_blank>https://ukdataservice.ac.uk/</a>.\n",
    "2. The location of the information we are interested in within the structure of the web page. This involves visually inspecting a web page's underlying code using a web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And **do** the following:\n",
    "1. Request the web page using its web address.\n",
    "2. Parse the structure of the web page so your programming language can work with its contents.\n",
    "3. Extract the information we are interested in.\n",
    "4. Write this information to a file for future use.\n",
    "\n",
    "For any programming task, it is useful to write out the steps needed to solve the problem: we call this *pseudo-code*, as it is captures the main tasks and the order in which they need to be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Details\n",
    "\n",
    "This is an example drawn from my (Diarmuid) own research. I am interested in the impact of COVID-19 on the foundation and dissolution charities across a number of countries. To study these phenomena I need the organisational status &mdash; foundation/dissolution date, organisational status &mdash; of individual charities. The Australian charity regulator provides high quality, open data on the organisational status of charities, with the exception of dissolution status. Therefore I wrote a script that takes a list of charity ids and scrapes information on organisational status from the regulator's website.\n",
    "\n",
    "Your task is to execute and complete sections of this web scraping script.\n",
    "\n",
    "It's a bit more complicated than what we've encountered so far, but gives you a sense of what web scraping for social research is really like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Identifying the web address\n",
    "\n",
    "An example of a charity's web page can be viewed at the following web address: https://www.acnc.gov.au/charity/3b7aa8b31249837c15657331aeb54821"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Locating information\n",
    "\n",
    "The information we need located in the *History* tab underneath the **Registration status history** heading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Visually inspecting the underlying HTML code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: inspect the web page of our example charity (https://www.acnc.gov.au/charity/3b7aa8b31249837c15657331aeb54821) and insert the relevant HTML into the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# INSERT HTML HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Requesting the web page\n",
    "\n",
    "**TASK**: import the `requests`, `csv` and `os` modules into this Python session (`datetime` and `BeautifulSoup` are already listed for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "from datetime import datetime # module for working with dates and time\n",
    "from bs4 import BeautifulSoup as soup # module for parsing web pages\n",
    "\n",
    "print(\"Succesfully imported necessary modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: fill in the blanks (e.g., # INSERT URL #) with the necessary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the URL where the web page can be accessed\n",
    "\n",
    "url = \"https://www.acnc.gov.au/charity/3b7aa8b31249837c15657331aeb54821\" # INSERT URL #\n",
    "\n",
    "\n",
    "# Request the web page from the URL\n",
    "\n",
    "response =  requests.get(url, allow_redirects = False, timeout = 5)# REQUEST THE URL #\n",
    "\n",
    "\n",
    "# Check if page was requested successfully #\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parsing the web page\n",
    "\n",
    "**TASK**: use the `soup()` method to parse the requested web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the contents of the web page from the response\n",
    "\n",
    "soup_response = soup(response.text, \"html.parser\") # Parse the text as a Beautiful Soup object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**QUESTION**: under which tag(s) is the *Registration status history* information found?\n",
    "\n",
    "**TASK**: find the section containing the *Registration status history* information and save it to a variable; view the contents of this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgdetails = soup_response.find(\"div\", class_=\"field field-name-acnc-node-charity-status-history field-type-ds field-label-hidden\")\n",
    "\n",
    "orgdetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: change the `orgtable` and `orgdetails` variable names below in order to match your choices from earlier, and execute the code\n",
    "\n",
    "**QUESTION**: explain what the `find_all(\"tr\")` method is doing, and how it fits with the preceeding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgtable = orgdetails.find(\"div\", class_=\"view-content\").find(\"tbody\").find_all(\"tr\")\n",
    "orgtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extracting information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: extract organisation status information by inserting code below (HINT: this information is contained in the second column in each row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for row in orgtable:\n",
    "    columns = row.find_all(\"td\") # extract all columns in each row\n",
    "    date = columns[0].text.strip() # organisation status date\n",
    "    status = columns[1].text.strip() # INSERT CODE HERE #\n",
    "    observation = date, status\n",
    "    \n",
    "    varnames = [\"status_date\", \"status\"]\n",
    "    with open(\"aus-charity-details.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f, varnames)\n",
    "        writer.writerow(varnames)\n",
    "        writer.writerow(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Saving results from the scrape\n",
    "\n",
    "**TASK**: list the contents of the folder where you saved the results of the scrape\n",
    "\n",
    "**TASK**: open the CSV file where you saved the results of the scrape &mdash; does it look as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check presence of file in \"downloads\" folder\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and read (import) its contents\n",
    "\n",
    "with open(\"aus-charity-details.csv\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(data)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINAL TASK**: execute the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'name' in globals():\n",
    "    print(\"{}, good effort on working through this practical!\".format(name))\n",
    "else:\n",
    "    print(\"You never told me your name at the beginning but you are still deserving of praise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations for working through this practical, you have now (at least to some degree) conducted a successful web scrape of real data. I'm sure you can imagine the immense potential of this method for collecting frequently updated social data in an automated and reliable manner.\n",
    "\n",
    "If you need help completing this practical then you can view the version containing solutions: *ncrm-web-scraping-practical-aus-charities-solution-2021-05-17.ipynb*.\n",
    "\n",
    "If you are confident in your abilities so far, then start implementing these techniques on your own web scraping idea by completing the following notebook: *ncrm-web-scraping-practical-own-idea-2021-05-17.ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--END OF FILE--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "256px",
    "width": "221px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
